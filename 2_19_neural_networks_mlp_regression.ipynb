{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL6X4BmiSMDg"
      },
      "source": [
        "# USING SKLEARN NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTB5b47lSMDh"
      },
      "source": [
        "# ON DIABETES DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8_SoRmXSMDh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "dataset = load_diabetes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQdd63m4SMDh",
        "outputId": "9269f15f-962c-4ddd-a7e2-75bd923e30a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990842, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06832974, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286377, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04687948,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452837, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00421986,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We cannot pass pandas dataframe for neaural network, it must be converted to numpy array dataset\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXi8wlAWSMDh",
        "outputId": "921478f4-733d-44f9-fdd1-1d5e88174acd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "       220.,  57.])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyTUePm1SMDh",
        "outputId": "ad5adda0-e50d-4825-e269-fa4a87953239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990842, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06832974, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286377, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04687948,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452837, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00421986,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50LyPHRESMDh",
        "outputId": "dda0c328-1f89-48b7-d871-d0d4362cd9f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "         0.01990842, -0.01764613],\n",
              "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "        -0.06832974, -0.09220405],\n",
              "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "         0.00286377, -0.02593034],\n",
              "       ...,\n",
              "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "        -0.04687948,  0.01549073],\n",
              "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "         0.04452837, -0.02593034],\n",
              "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "        -0.00421986,  0.00306441]])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep5qCNMGSMDi"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT7vJgkQSMDi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, random_state=100,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ter-J_6SSMDi",
        "outputId": "a393a9fa-71d2-4784-bdd7-eb1a2e794b50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.00914709,  0.05068012, -0.03099563, ..., -0.00259226,\n",
              "         0.00620932,  0.02791705],\n",
              "       [-0.04910502, -0.04464164,  0.00457217, ..., -0.00259226,\n",
              "        -0.03980959, -0.02178823],\n",
              "       [ 0.03081083, -0.04464164, -0.02021751, ..., -0.03949338,\n",
              "        -0.01090444, -0.0010777 ],\n",
              "       ...,\n",
              "       [ 0.07076875,  0.05068012, -0.00728377, ...,  0.1081111 ,\n",
              "         0.12901941,  0.0569118 ],\n",
              "       [ 0.0090156 ,  0.05068012,  0.01858372, ..., -0.00259226,\n",
              "         0.01630495, -0.01764613],\n",
              "       [ 0.04170844,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "        -0.01495648,  0.01134862]])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCkpKyQySMDi"
      },
      "outputs": [],
      "source": [
        "# Import Multi-layers Perceptron Model\n",
        "reg = MLPRegressor(hidden_layer_sizes=(3,3),#3 neurons and then 3 neurons\n",
        "                   verbose=2,#showing model running it can be 0 or 1 stand for not showing or showing\n",
        "                   activation=\"relu\" ,#activated function relu\n",
        "                   batch_size=100,#there are 100 batches to send to model\n",
        "                   random_state=1,\n",
        "                   max_iter=1000, #maximum iterations running\n",
        "                   learning_rate =\"adaptive\", #to allow model to decide better learning rate to run,it wont use fix learning rate 0.0001 to run\n",
        "                   solver='sgd', #sgd   --- rmsprop  ---- adam--- nadam #allow model to find the best value of the weight\n",
        "                   learning_rate_init=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9sI7yy_SMDi",
        "outputId": "e039f449-9968-4652-ec85-68d4a8e86bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 14813.74476479\n",
            "Iteration 2, loss = 14549.83895619\n",
            "Iteration 3, loss = 13631.24100532\n",
            "Iteration 4, loss = 9722.05010415\n",
            "Iteration 5, loss = 3809.09901404\n",
            "Iteration 6, loss = 3466.06329930\n",
            "Iteration 7, loss = 3110.92511914\n",
            "Iteration 8, loss = 2970.01096434\n",
            "Iteration 9, loss = 2884.18663965\n",
            "Iteration 10, loss = 2860.83886379\n",
            "Iteration 11, loss = 2798.10354335\n",
            "Iteration 12, loss = 2737.26619546\n",
            "Iteration 13, loss = 2710.68263488\n",
            "Iteration 14, loss = 2651.23861248\n",
            "Iteration 15, loss = 2562.57866784\n",
            "Iteration 16, loss = 2524.56924429\n",
            "Iteration 17, loss = 2454.03318623\n",
            "Iteration 18, loss = 2353.00861243\n",
            "Iteration 19, loss = 2263.50894117\n",
            "Iteration 20, loss = 2205.36594406\n",
            "Iteration 21, loss = 2092.97945983\n",
            "Iteration 22, loss = 2030.48719344\n",
            "Iteration 23, loss = 1941.61384074\n",
            "Iteration 24, loss = 1862.03462142\n",
            "Iteration 25, loss = 1809.84312316\n",
            "Iteration 26, loss = 1799.31414591\n",
            "Iteration 27, loss = 1725.10074649\n",
            "Iteration 28, loss = 1693.74363309\n",
            "Iteration 29, loss = 1677.78330309\n",
            "Iteration 30, loss = 1712.45576792\n",
            "Iteration 31, loss = 1684.56781354\n",
            "Iteration 32, loss = 1629.65288597\n",
            "Iteration 33, loss = 1632.27599876\n",
            "Iteration 34, loss = 1628.18491033\n",
            "Iteration 35, loss = 1586.07985425\n",
            "Iteration 36, loss = 1567.51038301\n",
            "Iteration 37, loss = 1601.56934736\n",
            "Iteration 38, loss = 1562.86690709\n",
            "Iteration 39, loss = 1576.74311066\n",
            "Iteration 40, loss = 1537.17977315\n",
            "Iteration 41, loss = 1535.90609514\n",
            "Iteration 42, loss = 1539.22177066\n",
            "Iteration 43, loss = 1536.40782639\n",
            "Iteration 44, loss = 1508.59844867\n",
            "Iteration 45, loss = 1511.78432834\n",
            "Iteration 46, loss = 1548.44266322\n",
            "Iteration 47, loss = 1543.41269584\n",
            "Iteration 48, loss = 1522.45432307\n",
            "Iteration 49, loss = 1679.64472073\n",
            "Iteration 50, loss = 1554.69027998\n",
            "Iteration 51, loss = 1496.85143278\n",
            "Iteration 52, loss = 1582.71319684\n",
            "Iteration 53, loss = 1505.39992480\n",
            "Iteration 54, loss = 1527.94094968\n",
            "Iteration 55, loss = 1527.95671098\n",
            "Iteration 56, loss = 1503.39082052\n",
            "Iteration 57, loss = 1500.62858020\n",
            "Iteration 58, loss = 1526.43684159\n",
            "Iteration 59, loss = 1503.83262409\n",
            "Iteration 60, loss = 1567.03846987\n",
            "Iteration 61, loss = 1517.73992523\n",
            "Iteration 62, loss = 1540.94551700\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000020\n",
            "Iteration 63, loss = 1647.07713911\n",
            "Iteration 64, loss = 1537.65355964\n",
            "Iteration 65, loss = 1498.91356454\n",
            "Iteration 66, loss = 1485.66044467\n",
            "Iteration 67, loss = 1490.32449118\n",
            "Iteration 68, loss = 1491.89972483\n",
            "Iteration 69, loss = 1486.90205161\n",
            "Iteration 70, loss = 1487.39355492\n",
            "Iteration 71, loss = 1480.85759394\n",
            "Iteration 72, loss = 1482.11717593\n",
            "Iteration 73, loss = 1481.44999236\n",
            "Iteration 74, loss = 1486.30378977\n",
            "Iteration 75, loss = 1480.14321808\n",
            "Iteration 76, loss = 1483.38331756\n",
            "Iteration 77, loss = 1481.28343568\n",
            "Iteration 78, loss = 1481.02510202\n",
            "Iteration 79, loss = 1483.82910491\n",
            "Iteration 80, loss = 1485.85386404\n",
            "Iteration 81, loss = 1480.46435942\n",
            "Iteration 82, loss = 1483.32958564\n",
            "Iteration 83, loss = 1485.86458915\n",
            "Iteration 84, loss = 1480.62265568\n",
            "Iteration 85, loss = 1481.10645431\n",
            "Iteration 86, loss = 1480.48977622\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000004\n",
            "Iteration 87, loss = 1479.38507666\n",
            "Iteration 88, loss = 1480.32792405\n",
            "Iteration 89, loss = 1480.67175228\n",
            "Iteration 90, loss = 1480.27878700\n",
            "Iteration 91, loss = 1480.50641485\n",
            "Iteration 92, loss = 1479.07351460\n",
            "Iteration 93, loss = 1479.89278694\n",
            "Iteration 94, loss = 1481.09007803\n",
            "Iteration 95, loss = 1480.02881693\n",
            "Iteration 96, loss = 1479.88242868\n",
            "Iteration 97, loss = 1480.05034356\n",
            "Iteration 98, loss = 1480.74079073\n",
            "Iteration 99, loss = 1478.09724414\n",
            "Iteration 100, loss = 1479.82782462\n",
            "Iteration 101, loss = 1479.80185295\n",
            "Iteration 102, loss = 1480.17682921\n",
            "Iteration 103, loss = 1480.36128663\n",
            "Iteration 104, loss = 1479.43143420\n",
            "Iteration 105, loss = 1479.06920283\n",
            "Iteration 106, loss = 1480.32637250\n",
            "Iteration 107, loss = 1479.40596196\n",
            "Iteration 108, loss = 1478.86859846\n",
            "Iteration 109, loss = 1479.09046961\n",
            "Iteration 110, loss = 1478.73550946\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000001\n",
            "Iteration 111, loss = 1479.03243609\n",
            "Iteration 112, loss = 1478.89745881\n",
            "Iteration 113, loss = 1478.70097760\n",
            "Iteration 114, loss = 1478.48615589\n",
            "Iteration 115, loss = 1479.00826971\n",
            "Iteration 116, loss = 1478.58410775\n",
            "Iteration 117, loss = 1478.79208642\n",
            "Iteration 118, loss = 1478.51916649\n",
            "Iteration 119, loss = 1478.53619777\n",
            "Iteration 120, loss = 1478.47794999\n",
            "Iteration 121, loss = 1478.47456055\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPRegressor(batch_size=100, hidden_layer_sizes=(3, 3),\n",
              "             learning_rate='adaptive', learning_rate_init=0.0001, max_iter=1000,\n",
              "             random_state=1, solver='sgd', verbose=2)"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fitting data\n",
        "reg.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnK9buYiSMDi",
        "outputId": "4410ec3b-9c98-423a-deb1-4a5fdf294aaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.11274486,  0.22530822, -0.6647727 ],\n",
              "        [-0.26857706, -0.83520862, -2.75281987],\n",
              "        [-0.42628829,  0.83840971,  6.72780722],\n",
              "        [ 0.05274154,  0.45535171,  4.16157518],\n",
              "        [-0.40157018,  0.41239065, -0.83850742],\n",
              "        [ 0.23161966, -0.40286896, -1.17392343],\n",
              "        [-0.48861777, -0.67815795, -1.96477602],\n",
              "        [ 0.63624198, -0.15804896,  1.5929925 ],\n",
              "        [ 0.51141198,  1.42197183,  5.43398459],\n",
              "        [-0.62630101, -0.40671077,  1.34185534]]),\n",
              " array([[ 0.06633055,  0.3837541 , -0.36896862],\n",
              "        [ 0.41338342,  1.65770272, -0.96368842],\n",
              "        [ 0.47502687,  8.59009404, -0.38299637]]),\n",
              " array([[ 0.48998996],\n",
              "        [ 9.30194842],\n",
              "        [-0.41839341]])]"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg.coefs_ #weigth matrix (checking how many weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzcTbcseSMDi",
        "outputId": "4bbb71b2-61b5-48a4-f92c-5f6d40f08056"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([-0.54573919,  0.14443936,  1.42692424]),\n",
              " array([-0.5822138 ,  3.72611241, -1.15455753]),\n",
              " array([1.56665839])]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg.intercepts_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVFoM0b7SMDi",
        "outputId": "735faf96-158c-4bfc-b008-cd64e90c8258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'logistic',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 40,\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (2, 3, 5),\n",
              " 'learning_rate': 'adaptive',\n",
              " 'learning_rate_init': 0.0001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 2000,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': 1,\n",
              " 'shuffle': True,\n",
              " 'solver': 'sgd',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 2,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2OwI8t6SMDj",
        "outputId": "a9b2a474-1b28-44f9-ae9c-633ca03251a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLPRegressor(activation='logistic', batch_size=40, hidden_layer_sizes=(2, 3, 5),\n",
              "             learning_rate='adaptive', learning_rate_init=0.0001, max_iter=1000,\n",
              "             random_state=1, solver='sgd', verbose=22)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLoD_jgLSMDj",
        "outputId": "60f7fda4-6ca2-451b-cb37-2d34930865bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 42.,  72., 139.,  74., 109.,  68., 252., 245., 199., 279., 268.,\n",
              "       244., 288., 296., 129., 200.,  85.,  87., 178., 136., 277., 163.,\n",
              "        49., 118., 246.,  68., 281., 200., 122., 277.,  92., 103., 146.,\n",
              "       124., 126.,  67., 258., 156., 232., 131., 140., 198.,  96., 168.,\n",
              "        89., 161., 182., 101., 217.,  49., 310., 128.,  52.,  97.,  92.,\n",
              "        94.,  94., 270.,  98., 178.,  31., 185.,  63.,  99., 121.,  60.,\n",
              "        84.,  97.,  59., 230., 131.,  83., 138., 191.,  87., 174.,  69.,\n",
              "        75.,  88.,  53.,  49.,  89., 168.,  63., 214., 179., 196., 114.,\n",
              "       104.])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LESbzNfXSMDj",
        "outputId": "ee0da3e0-a886-4e5a-80a2-d177896ea301"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 84.01227541,  48.32847005, 183.22841351,  85.45863654,\n",
              "       104.30094234, 123.15720952, 153.85038122, 278.44316472,\n",
              "       105.9992102 , 218.01527996, 210.54642793, 178.69630874,\n",
              "       208.19594039, 221.54568255, 101.09557858, 145.59793179,\n",
              "        63.91787587,  88.80906536, 189.94212387, 152.93770551,\n",
              "       267.01899334, 212.25052735,  97.26913094, 156.30081908,\n",
              "       232.23334656, 117.38328333, 276.34759719, 113.65136801,\n",
              "       192.10931105, 172.10063904, 119.94498719, 145.8327889 ,\n",
              "       140.73075059, 125.74985491, 172.31402806, 187.00119467,\n",
              "       242.19076582, 150.44318431, 224.98586113, 202.22439759,\n",
              "       122.6553017 , 157.14641202,  82.40261307, 144.64814314,\n",
              "        74.09912369, 187.35179981, 147.13255563,  92.11681025,\n",
              "       244.37136552, 136.68145637, 273.743842  ,  79.63932375,\n",
              "       203.88733723, 145.22567253,  83.38894246, 156.71534966,\n",
              "        92.73177866, 291.21827801,  86.52057097, 119.83780335,\n",
              "       100.44835304, 140.36585584, 125.06481297, 227.06014773,\n",
              "       167.78057806, 136.70031135, 122.41541814, 109.63728978,\n",
              "        67.29911875, 140.0606526 , 119.77053466,  72.40973418,\n",
              "        79.27213393, 190.447086  , 107.16203536, 167.96820108,\n",
              "       110.80660194,  70.24591759, 112.42032497,  79.77254879,\n",
              "        96.31512916, 113.68809693, 121.12484884, 101.53096222,\n",
              "       121.65061046, 167.06118684, 159.09701673,  86.56585199,\n",
              "        68.67042246])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred=reg.predict(X_test) #predict the output\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inEUP9jZSMDj",
        "outputId": "8b7c106a-8f46-43bb-8164-e780ade58509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.19398725467508282"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_score(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NrK1latSMDj"
      },
      "source": [
        "# ----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GenRefYcSMDj"
      },
      "source": [
        "# USING KERAS MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlTVjDjySMDj"
      },
      "outputs": [],
      "source": [
        "#Load dependencies\n",
        "\n",
        "from keras.models import Sequential #sequential layers\n",
        "from keras.layers import Dense\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M15aaUPbSMDj"
      },
      "source": [
        "## ON DIABETES DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFkngr3ZSMDj",
        "outputId": "de6e4d8e-45f6-4563-cd19-f7816c8e9480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990842, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06832974, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286377, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04687948,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452837, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00421986,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "dataset = load_diabetes()\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1aj4UFsSMDj",
        "outputId": "42a52929-114f-4d3f-93cf-816965412e92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "       220.,  57.])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split"
      ],
      "metadata": {
        "id": "OTJ3cIT1mckq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnV4in3bSMDj"
      },
      "outputs": [],
      "source": [
        "dataset\n",
        "x_train, y_train = dataset.data, dataset.target\n",
        "#x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7PJahMHSMDj",
        "outputId": "847b6126-3142-4634-a6e8-1534d6df8025"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(442, 10)"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTEgtV89SMDk",
        "outputId": "91cee84c-93bf-40f2-a4e2-e13eeb30602d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (10,)\n"
          ]
        }
      ],
      "source": [
        "# Set the input shape\n",
        "input_shape = (10,) #10 features ['age','sex','bmi','bp','s1','s2','s3','s4','s5','s6'],\n",
        "\n",
        "print(f\"Feature shape: {input_shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA34MH_rSMDk"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "\n",
        "model = Sequential() #initialize model (it is a blank model so we must add dense layers below)\n",
        "\n",
        "model.add(Dense(16, input_shape=input_shape, activation='relu')) #hidden layers that have 10 features, 16 neurons, activation function\n",
        "\n",
        "model.add(Dense(8, activation='relu')) # hidden layers with 8 neurons, activation function\n",
        "\n",
        "model.add(Dense(1, activation='softmax')) # output layers with 1 neurons, activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M30N0teWSMDk"
      },
      "source": [
        "# Types of Activation Functions\n",
        "\n",
        "* sigmoid  -- Main advantage is simple and good for classifier. But Big disadvantage of the function is that it It gives rise to a problem of vanishing gradients because Its output isnt zero centered. It makes the gradient updates go too far in different directions. 0 < output < 1, and it makes optimization harder. That takes very high computational time in hidden layer of neural network\n",
        "\n",
        "\n",
        "\n",
        "* tanh -- Tanh help to solve non zero centered problem of sigmoid function.\n",
        "\n",
        "\n",
        "* relu   -- avoids and rectifies vanishing gradient problem and less computationally expensive --- dead neurons -- faster\n",
        "* leaky relu   --- solves dead nerons\n",
        "* parametrised relu   - better\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  softmax-- output layer --- The main advantage of the function is able to handle multiple classes.   --- sum of 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfsGe2fgSMDk",
        "outputId": "ababe963-b2de-40da-f409-fe7bc9f2c4aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x23462393730>"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoP4s53LSMDk"
      },
      "outputs": [],
      "source": [
        "# Configure the model\n",
        "model.compile(loss='mean_absolute_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=['mean_squared_error'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRYUpKRkSMDk",
        "outputId": "2783adb9-8708-40aa-b380-6e1de2f2aa57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 528ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 95/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 75ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 150.4788 - mean_squared_error: 28447.5957 - val_loss: 153.7303 - val_mean_squared_error: 30054.7871\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x23463494a60>"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#and start training\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=100, #how many times we send data to model to train it\n",
        "          batch_size=442,\n",
        "          verbose=1,\n",
        "          validation_split=0.2\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5ALBvtqSMDk",
        "outputId": "a1d5917f-637d-4b8a-bf04-a44842868f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 16)                176       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QemQf2cZSMDl",
        "outputId": "cae28487-53c2-4aef-a4d3-e0f8e76b8c01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_6/kernel:0' shape=(10, 16) dtype=float32, numpy=\n",
              " array([[ 0.4100216 ,  0.3171019 , -0.263442  , -0.02229092, -0.13075453,\n",
              "          0.09087461,  0.3137706 ,  0.33249635,  0.01006284, -0.02673808,\n",
              "          0.29331052, -0.3350458 ,  0.24026608,  0.09254235, -0.2784404 ,\n",
              "         -0.398059  ],\n",
              "        [-0.40266585,  0.37535214, -0.30472243,  0.2655446 ,  0.29158062,\n",
              "         -0.18548894, -0.02932858,  0.03158605, -0.3627964 ,  0.17912704,\n",
              "          0.3927614 ,  0.14427567,  0.25573593, -0.10355842, -0.16074306,\n",
              "         -0.31284702],\n",
              "        [-0.3947323 , -0.08846587, -0.27659732,  0.39913714,  0.2596928 ,\n",
              "         -0.37497944,  0.09994924,  0.04355562, -0.10676932, -0.30777058,\n",
              "          0.43008953, -0.30852592,  0.4789425 ,  0.2952879 , -0.25313234,\n",
              "         -0.33153653],\n",
              "        [ 0.22778356,  0.27652895,  0.41798908,  0.23081124,  0.0934974 ,\n",
              "         -0.24975823, -0.04006842, -0.02322274, -0.05432668,  0.2592383 ,\n",
              "          0.10849202, -0.05744302, -0.25047737, -0.01489919,  0.44030046,\n",
              "          0.3614087 ],\n",
              "        [-0.02009943, -0.27998155,  0.21324968, -0.11042202, -0.15158936,\n",
              "          0.22517943,  0.47821867,  0.06674349, -0.12889612, -0.04453725,\n",
              "          0.44438744, -0.07609051, -0.19749117, -0.2493356 ,  0.3841517 ,\n",
              "          0.21055084],\n",
              "        [ 0.4597087 , -0.4414167 , -0.20495972,  0.36176854, -0.12041107,\n",
              "         -0.32599056, -0.366853  ,  0.34218073,  0.28492993, -0.13676691,\n",
              "         -0.41989478,  0.1301238 , -0.44026336,  0.33341795, -0.05891076,\n",
              "         -0.03125274],\n",
              "        [ 0.1953587 , -0.22881377, -0.22317612,  0.320315  ,  0.08727694,\n",
              "          0.37082475,  0.40343952, -0.24021205,  0.42662495, -0.0361647 ,\n",
              "         -0.43664068,  0.39730656, -0.46680903, -0.16490802,  0.36833334,\n",
              "         -0.3885778 ],\n",
              "        [-0.19832498,  0.10576934, -0.15551281,  0.29516912,  0.08185172,\n",
              "         -0.17974067, -0.41064626, -0.18966436, -0.17570937,  0.25131166,\n",
              "         -0.21802011,  0.3236432 , -0.11040345,  0.40127212, -0.47101113,\n",
              "          0.15330255],\n",
              "        [-0.37546656,  0.1338948 ,  0.36234057,  0.22683305, -0.16978815,\n",
              "         -0.00905871,  0.15097088,  0.05066717,  0.16354519,  0.22586113,\n",
              "          0.40726388, -0.35914797, -0.11014462,  0.21677959,  0.07774824,\n",
              "          0.47857392],\n",
              "        [ 0.1672225 ,  0.09660411, -0.17818269, -0.40201715,  0.14894778,\n",
              "          0.43080914,  0.0966664 , -0.10965842, -0.19020575, -0.3065365 ,\n",
              "         -0.3956284 ,  0.00053132,  0.21096641, -0.20304427, -0.1374611 ,\n",
              "         -0.24229734]], dtype=float32)>,\n",
              " <tf.Variable 'dense_6/bias:0' shape=(16,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_7/kernel:0' shape=(16, 8) dtype=float32, numpy=\n",
              " array([[ 0.12807715, -0.20333326, -0.3329562 ,  0.3458984 , -0.47888207,\n",
              "         -0.25543642,  0.12174428,  0.32053232],\n",
              "        [ 0.02710688,  0.00965488,  0.39916646,  0.4858662 , -0.38576388,\n",
              "          0.4873525 ,  0.46990347,  0.02084863],\n",
              "        [ 0.35638165, -0.31912923, -0.06823778,  0.41081703, -0.49934053,\n",
              "         -0.02611244,  0.41320252, -0.34440994],\n",
              "        [-0.14017224,  0.4947245 , -0.2125113 ,  0.37428892, -0.3067311 ,\n",
              "          0.01992822, -0.38017774,  0.14169943],\n",
              "        [-0.2738124 , -0.2127335 , -0.24498785,  0.3582493 ,  0.14894176,\n",
              "          0.4389    ,  0.14659822,  0.13359833],\n",
              "        [-0.4148866 ,  0.49921632, -0.45489657, -0.10640824, -0.01501405,\n",
              "          0.03527141,  0.02366436, -0.46323204],\n",
              "        [-0.10401607,  0.09062946, -0.3595252 , -0.11662054,  0.48713517,\n",
              "         -0.1424886 ,  0.446849  , -0.46850324],\n",
              "        [-0.3886242 ,  0.4015088 ,  0.47748435,  0.33792305,  0.18090677,\n",
              "          0.37352633, -0.47720444,  0.18578732],\n",
              "        [-0.07515705, -0.00632691, -0.31534505,  0.0844841 ,  0.11972582,\n",
              "         -0.19084072,  0.04126132, -0.2637496 ],\n",
              "        [ 0.41914308,  0.28637743, -0.3879975 ,  0.4147508 ,  0.18757331,\n",
              "          0.3982184 , -0.095801  ,  0.22043836],\n",
              "        [ 0.46668077, -0.24849045,  0.10695887, -0.4715792 , -0.47635102,\n",
              "          0.2651583 ,  0.3373915 , -0.25305974],\n",
              "        [ 0.06651938, -0.04461396,  0.20859182,  0.10366213,  0.26832914,\n",
              "          0.13334966,  0.05185592,  0.33767068],\n",
              "        [-0.23654878,  0.14952016,  0.36107612,  0.30038226,  0.38248503,\n",
              "          0.08392406, -0.22074413, -0.37208545],\n",
              "        [-0.16196895,  0.25843918,  0.45542347,  0.09685588,  0.3185538 ,\n",
              "         -0.43356752,  0.28702343, -0.37961924],\n",
              "        [-0.4197427 ,  0.00746822,  0.07394063,  0.10041082,  0.32024503,\n",
              "          0.24579751, -0.46089613, -0.21636844],\n",
              "        [ 0.28164375,  0.06451845, -0.1680423 ,  0.07671964,  0.38249218,\n",
              "         -0.10065281,  0.15803003,  0.27995956]], dtype=float32)>,\n",
              " <tf.Variable 'dense_7/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_8/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
              " array([[-0.4439948 ],\n",
              "        [ 0.17864794],\n",
              "        [ 0.7199664 ],\n",
              "        [ 0.14137954],\n",
              "        [-0.41716078],\n",
              "        [-0.07551831],\n",
              "        [ 0.30527246],\n",
              "        [-0.26349205]], dtype=float32)>,\n",
              " <tf.Variable 'dense_8/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d1rvdmtSMDl",
        "outputId": "c3802278-efa3-411e-9d53-f62ce4980876"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 10)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW-SAa5kSMDl",
        "outputId": "bda03080-a8df-4823-a931-65fd0c0b4df3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 1)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQtSRubkSMDl",
        "outputId": "13738057-09e6-4ba9-d9f1-07d6f0fc14cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.layers.core.dense.Dense at 0x234531af970>,\n",
              " <keras.layers.core.dense.Dense at 0x234531af760>,\n",
              " <keras.layers.core.dense.Dense at 0x2345e2104c0>]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmdPP4OFSMDl"
      },
      "source": [
        "# VISUALIZATION OF LAYERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FVe1qJhSMDl"
      },
      "source": [
        "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w0bVZVtSMDl"
      },
      "source": [
        "pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRUSD5ZxSMDm",
        "outputId": "24ecb2db-adf3-49b6-d5bb-32af609f7bb0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}